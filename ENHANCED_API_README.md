# Enhanced ArXiv API Client

åŸºäº [arXiv API å®˜æ–¹æ–‡æ¡£](https://info.arxiv.org/help/api/index.html) é‡æ–°æ„å»ºçš„å¢å¼ºç‰ˆ arXiv API å®¢æˆ·ç«¯ã€‚

## ä¸»è¦ç‰¹æ€§

### ğŸš€ å¢å¼ºåŠŸèƒ½
- **ç»“æ„åŒ–æŸ¥è¯¢æ”¯æŒ**: ä½¿ç”¨ `SearchQuery` å¯¹è±¡è¿›è¡Œç²¾ç¡®çš„å­—æ®µæœç´¢
- **å¤šå­—æ®µæœç´¢**: æ”¯æŒæ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ã€ç±»åˆ«ç­‰å¤šä¸ªå­—æ®µçš„ç»„åˆæœç´¢
- **æ—¥æœŸèŒƒå›´è¿‡æ»¤**: çµæ´»çš„æ—¥æœŸèŒƒå›´æŸ¥è¯¢åŠŸèƒ½
- **å¤šç§æ’åºé€‰é¡¹**: æŒ‰ç›¸å…³æ€§ã€æäº¤æ—¥æœŸã€æ›´æ–°æ—¥æœŸæ’åº
- **ç±»åˆ«è¿‡æ»¤**: æ”¯æŒå•ä¸ªæˆ–å¤šä¸ª arXiv ç±»åˆ«è¿‡æ»¤
- **ID æ‰¹é‡æŸ¥è¯¢**: é€šè¿‡ arXiv ID åˆ—è¡¨æ‰¹é‡è·å–è®ºæ–‡
- **ä¾¿åˆ©å‡½æ•°**: æä¾›å¸¸ç”¨æœç´¢æ¨¡å¼çš„å¿«æ·å‡½æ•°

### ğŸ›¡ï¸ å¯é æ€§æ”¹è¿›
- **å®Œæ•´çš„é”™è¯¯å¤„ç†**: ç½‘ç»œé”™è¯¯ã€è§£æé”™è¯¯ã€éªŒè¯é”™è¯¯çš„åˆ†ç±»å¤„ç†
- **è‡ªåŠ¨é‡è¯•æœºåˆ¶**: æŒ‡æ•°é€€é¿çš„è¯·æ±‚é‡è¯•ç­–ç•¥
- **å‚æ•°éªŒè¯**: ä¸¥æ ¼çš„è¾“å…¥å‚æ•°éªŒè¯
- **ä¼šè¯ç®¡ç†**: è‡ªåŠ¨çš„ HTTP ä¼šè¯ç®¡ç†å’Œèµ„æºæ¸…ç†

### ğŸ”§ å‘åå…¼å®¹
- **æ— ç¼é›†æˆ**: ä¸ç°æœ‰ `ArxivDownloader` ç±»å®Œå…¨å…¼å®¹
- **æ¸è¿›å¼å‡çº§**: å¯ä»¥é€æ­¥è¿ç§»åˆ°æ–° API
- **ä¿æŒæ¥å£**: åŸæœ‰æ¥å£ç»§ç»­å¯ç”¨

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from enhanced_arxiv_api import EnhancedArxivAPI

# åˆ›å»º API å®¢æˆ·ç«¯
with EnhancedArxivAPI() as api:
    # åŸºæœ¬å…³é”®è¯æœç´¢
    papers = api.search_papers(
        query="machine learning",
        max_results=10
    )
    
    for paper in papers:
        print(f"Title: {paper.title}")
        print(f"Authors: {', '.join(paper.authors)}")
        print(f"Categories: {', '.join(paper.categories)}")
        print()
```

### ç»“æ„åŒ–æŸ¥è¯¢

```python
from enhanced_arxiv_api import (
    EnhancedArxivAPI, 
    SearchQuery, 
    SearchField, 
    SortBy, 
    SortOrder
)

with EnhancedArxivAPI() as api:
    # åœ¨æ ‡é¢˜ä¸­æœç´¢ "transformer"
    query = SearchQuery(
        terms=["transformer"],
        field=SearchField.TITLE
    )
    
    papers = api.search_papers(
        query=query,
        max_results=5,
        sort_by=SortBy.SUBMITTED_DATE,
        sort_order=SortOrder.DESCENDING
    )
```

### å¤šå­—æ®µç»„åˆæŸ¥è¯¢

```python
# ç»„åˆå¤šä¸ªæœç´¢æ¡ä»¶
queries = [
    SearchQuery(terms=["neural"], field=SearchField.TITLE),
    SearchQuery(terms=["attention"], field=SearchField.ABSTRACT)
]

papers = api.search_papers(
    query=queries,
    categories=["cs.AI", "cs.LG"],
    max_results=10
)
```

### æ—¥æœŸèŒƒå›´è¿‡æ»¤

```python
from enhanced_arxiv_api import DateRange
from datetime import datetime, timedelta

# æœç´¢æœ€è¿‘ 30 å¤©çš„è®ºæ–‡
end_date = datetime.now()
start_date = end_date - timedelta(days=30)

date_range = DateRange(
    start_date=start_date.strftime('%Y-%m-%d'),
    end_date=end_date.strftime('%Y-%m-%d')
)

papers = api.search_papers(
    query="deep learning",
    date_range=date_range,
    max_results=20
)
```

### æŒ‰ ID è·å–ç‰¹å®šè®ºæ–‡

```python
# è·å–ç‰¹å®šè®ºæ–‡
famous_papers = [
    "1706.03762",  # Attention Is All You Need
    "1810.04805",  # BERT
    "2005.14165",  # GPT-3
]

papers = api.search_papers(
    id_list=famous_papers,
    max_results=10
)
```

## ä¾¿åˆ©å‡½æ•°

ä¸ºå¸¸è§çš„æœç´¢æ¨¡å¼æä¾›äº†ä¾¿åˆ©å‡½æ•°ï¼š

```python
from enhanced_arxiv_api import (
    search_by_keyword,
    search_by_author,
    search_by_category,
    get_recent_papers
)

# å…³é”®è¯æœç´¢
papers = search_by_keyword("quantum computing", max_results=10)

# ä½œè€…æœç´¢
papers = search_by_author("Geoffrey Hinton", max_results=10)

# ç±»åˆ«æœç´¢
papers = search_by_category("cs.CV", max_results=10)

# è·å–æœ€è¿‘è®ºæ–‡
papers = get_recent_papers("cs.AI", days=7, max_results=20)
```

## ä¸ç°æœ‰ä»£ç é›†æˆ

### åœ¨ ArxivDownloader ä¸­ä½¿ç”¨

```python
from arxiv_downloader import ArxivDownloader
from enhanced_arxiv_api import SearchField, SortBy, SortOrder

downloader = ArxivDownloader()

# ä½¿ç”¨å¢å¼ºæœç´¢åŠŸèƒ½
papers = downloader.search_papers_enhanced(
    query="deep learning",
    search_field=SearchField.TITLE,
    categories=["cs.LG"],
    max_results=10,
    sort_by=SortBy.SUBMITTED_DATE,
    sort_order=SortOrder.DESCENDING
)

# ä¸‹è½½è®ºæ–‡
for paper in papers:
    downloader.download_paper(paper)
```

## æœç´¢å­—æ®µè¯´æ˜

| å­—æ®µ | æšä¸¾å€¼ | æè¿° |
|------|--------|------|
| å…¨éƒ¨å­—æ®µ | `SearchField.ALL` | åœ¨æ‰€æœ‰å­—æ®µä¸­æœç´¢ |
| æ ‡é¢˜ | `SearchField.TITLE` | ä»…åœ¨è®ºæ–‡æ ‡é¢˜ä¸­æœç´¢ |
| ä½œè€… | `SearchField.AUTHOR` | ä»…åœ¨ä½œè€…ä¿¡æ¯ä¸­æœç´¢ |
| æ‘˜è¦ | `SearchField.ABSTRACT` | ä»…åœ¨è®ºæ–‡æ‘˜è¦ä¸­æœç´¢ |
| è¯„è®º | `SearchField.COMMENT` | ä»…åœ¨è®ºæ–‡è¯„è®ºä¸­æœç´¢ |
| æœŸåˆŠå¼•ç”¨ | `SearchField.JOURNAL_REF` | ä»…åœ¨æœŸåˆŠå¼•ç”¨ä¸­æœç´¢ |
| ç±»åˆ« | `SearchField.CATEGORY` | ä»…åœ¨ä¸»é¢˜ç±»åˆ«ä¸­æœç´¢ |
| æŠ¥å‘Šç¼–å· | `SearchField.REPORT_NUM` | ä»…åœ¨æŠ¥å‘Šç¼–å·ä¸­æœç´¢ |
| arXiv ID | `SearchField.ID` | ä»…åœ¨ arXiv ID ä¸­æœç´¢ |
| æäº¤æ—¥æœŸ | `SearchField.SUBMITTED_DATE` | æŒ‰æäº¤æ—¥æœŸæœç´¢ |
| æ›´æ–°æ—¥æœŸ | `SearchField.LAST_UPDATED_DATE` | æŒ‰æœ€åæ›´æ–°æ—¥æœŸæœç´¢ |

## æ’åºé€‰é¡¹

### æ’åºæ ‡å‡† (SortBy)
- `SortBy.RELEVANCE`: æŒ‰ç›¸å…³æ€§æ’åºï¼ˆé»˜è®¤ï¼‰
- `SortBy.LAST_UPDATED_DATE`: æŒ‰æœ€åæ›´æ–°æ—¥æœŸæ’åº
- `SortBy.SUBMITTED_DATE`: æŒ‰æäº¤æ—¥æœŸæ’åº

### æ’åºé¡ºåº (SortOrder)
- `SortOrder.DESCENDING`: é™åºæ’åˆ—ï¼ˆé»˜è®¤ï¼‰
- `SortOrder.ASCENDING`: å‡åºæ’åˆ—

## å¸¸ç”¨ arXiv ç±»åˆ«

### è®¡ç®—æœºç§‘å­¦
- `cs.AI`: äººå·¥æ™ºèƒ½
- `cs.LG`: æœºå™¨å­¦ä¹ 
- `cs.CV`: è®¡ç®—æœºè§†è§‰
- `cs.CL`: è®¡ç®—è¯­è¨€å­¦
- `cs.NE`: ç¥ç»ä¸è¿›åŒ–è®¡ç®—
- `cs.RO`: æœºå™¨äººå­¦

### æ•°å­¦
- `math.ST`: ç»Ÿè®¡å­¦
- `math.OC`: ä¼˜åŒ–ä¸æ§åˆ¶
- `math.PR`: æ¦‚ç‡è®º

### ç‰©ç†å­¦
- `physics.data-an`: æ•°æ®åˆ†æ
- `quant-ph`: é‡å­ç‰©ç†

### ç»Ÿè®¡å­¦
- `stat.ML`: æœºå™¨å­¦ä¹ ç»Ÿè®¡
- `stat.TH`: ç»Ÿè®¡ç†è®º

## é”™è¯¯å¤„ç†

```python
from models import ValidationError, NetworkError, ParseError

try:
    with EnhancedArxivAPI() as api:
        papers = api.search_papers(
            query="machine learning",
            max_results=10
        )
except ValidationError as e:
    print(f"å‚æ•°éªŒè¯é”™è¯¯: {e}")
except NetworkError as e:
    print(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
except ParseError as e:
    print(f"å“åº”è§£æé”™è¯¯: {e}")
except Exception as e:
    print(f"å…¶ä»–é”™è¯¯: {e}")
```

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰ API å®¢æˆ·ç«¯

```python
api = EnhancedArxivAPI(
    timeout=30,           # è¯·æ±‚è¶…æ—¶æ—¶é—´
    max_retries=5,        # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay=2.0,      # é‡è¯•å»¶è¿Ÿ
    user_agent="MyApp/1.0" # è‡ªå®šä¹‰ User-Agent
)
```

### å¤æ‚æŸ¥è¯¢ç¤ºä¾‹

```python
# æœç´¢æœ€è¿‘ä¸€å¹´å†…ï¼Œåœ¨ AI æˆ– ML ç±»åˆ«ä¸­ï¼Œ
# æ ‡é¢˜åŒ…å« "transformer" æˆ– "attention" çš„è®ºæ–‡
from datetime import datetime, timedelta

end_date = datetime.now()
start_date = end_date - timedelta(days=365)

date_range = DateRange(
    start_date=start_date.strftime('%Y-%m-%d'),
    end_date=end_date.strftime('%Y-%m-%d')
)

query = SearchQuery(
    terms=["transformer", "attention"],
    field=SearchField.TITLE,
    operator="OR"
)

papers = api.search_papers(
    query=query,
    categories=["cs.AI", "cs.LG"],
    date_range=date_range,
    max_results=50,
    sort_by=SortBy.SUBMITTED_DATE,
    sort_order=SortOrder.DESCENDING
)
```

## æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜æœºåˆ¶
- æœç´¢ç»“æœè‡ªåŠ¨ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚
- ç¼“å­˜é”®åŸºäºæŸ¥è¯¢å‚æ•°ç”Ÿæˆ
- æ”¯æŒå¢å¼ºæœç´¢çš„ç¼“å­˜

### è¯·æ±‚ä¼˜åŒ–
- è‡ªåŠ¨ä¼šè¯ç®¡ç†
- è¿æ¥æ± å¤ç”¨
- æŒ‡æ•°é€€é¿é‡è¯•
- åˆç†çš„è¶…æ—¶è®¾ç½®

## æµ‹è¯•å’Œç¤ºä¾‹

### è¿è¡Œæµ‹è¯•
```bash
# è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•
python3 test_enhanced_api.py

# è¿è¡Œè¯¦ç»†ç¤ºä¾‹
python3 enhanced_api_examples.py
```

### ç¤ºä¾‹æ–‡ä»¶
- `test_enhanced_api.py`: åŸºæœ¬åŠŸèƒ½æµ‹è¯•
- `enhanced_api_examples.py`: è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹
- `ENHANCED_API_README.md`: æœ¬æ–‡æ¡£

## API å‚è€ƒ

### EnhancedArxivAPI ç±»

#### æ„é€ å‡½æ•°
```python
EnhancedArxivAPI(
    timeout: int = 30,
    max_retries: int = 3,
    retry_delay: float = 1.0,
    user_agent: str = "Enhanced-ArXiv-Client/1.0"
)
```

#### ä¸»è¦æ–¹æ³•

##### search_papers
```python
search_papers(
    query: Union[str, SearchQuery, List[SearchQuery]] = None,
    id_list: Optional[List[str]] = None,
    date_range: Optional[DateRange] = None,
    categories: Optional[List[str]] = None,
    max_results: int = 10,
    start: int = 0,
    sort_by: SortBy = SortBy.RELEVANCE,
    sort_order: SortOrder = SortOrder.DESCENDING
) -> List[Paper]
```

##### get_paper_by_id
```python
get_paper_by_id(
    arxiv_id: str, 
    version: Optional[int] = None
) -> Optional[Paper]
```

### æ•°æ®ç±»

#### SearchQuery
```python
@dataclass
class SearchQuery:
    terms: List[str]
    field: SearchField = SearchField.ALL
    operator: str = "AND"  # AND, OR, ANDNOT
```

#### DateRange
```python
@dataclass
class DateRange:
    start_date: Optional[str] = None  # YYYY-MM-DD
    end_date: Optional[str] = None    # YYYY-MM-DD
    field: SearchField = SearchField.SUBMITTED_DATE
```

#### Paper (å¢å¼ºç‰ˆ)
```python
@dataclass
class Paper:
    id: str
    title: str
    authors: List[str]
    abstract: str
    pdf_url: str
    published: str
    categories: List[str]
    comment: Optional[str] = None      # æ–°å¢
    journal_ref: Optional[str] = None  # æ–°å¢
    doi: Optional[str] = None          # æ–°å¢
```

## è¿ç§»æŒ‡å—

### ä»æ—§ API è¿ç§»

#### åŸºæœ¬æœç´¢
```python
# æ—§æ–¹å¼
downloader = ArxivDownloader()
papers = downloader.search_papers("machine learning", max_results=10)

# æ–°æ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
papers = downloader.search_papers("machine learning", max_results=10)

# æ–°æ–¹å¼ï¼ˆå¢å¼ºåŠŸèƒ½ï¼‰
papers = downloader.search_papers_enhanced(
    query="machine learning",
    max_results=10
)
```

#### ç±»åˆ«æœç´¢
```python
# æ—§æ–¹å¼
papers = downloader.search_papers(
    "machine learning", 
    categories=["cs.LG"]
)

# æ–°æ–¹å¼
papers = downloader.search_papers_enhanced(
    categories=["cs.LG"]
)
```

## æœ€ä½³å®è·µ

### 1. ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
```python
# æ¨è
with EnhancedArxivAPI() as api:
    papers = api.search_papers(query="machine learning")

# æˆ–è€…æ‰‹åŠ¨ç®¡ç†
api = EnhancedArxivAPI()
try:
    papers = api.search_papers(query="machine learning")
finally:
    api.close()
```

### 2. åˆç†è®¾ç½®æœç´¢å‚æ•°
```python
# é¿å…è¿‡å¤§çš„ max_results
papers = api.search_papers(
    query="machine learning",
    max_results=100  # è€ƒè™‘åˆ†é¡µ
)

# ä½¿ç”¨å…·ä½“çš„æœç´¢å­—æ®µ
query = SearchQuery(
    terms=["transformer"],
    field=SearchField.TITLE  # æ¯” ALL æ›´ç²¾ç¡®
)
```

### 3. é”™è¯¯å¤„ç†
```python
from models import ValidationError, NetworkError, ParseError

try:
    papers = api.search_papers(query="machine learning")
except ValidationError:
    # å¤„ç†å‚æ•°é”™è¯¯
    pass
except NetworkError:
    # å¤„ç†ç½‘ç»œé”™è¯¯ï¼Œå¯èƒ½éœ€è¦é‡è¯•
    pass
except ParseError:
    # å¤„ç†è§£æé”™è¯¯
    pass
```

### 4. æ€§èƒ½ä¼˜åŒ–
```python
# åˆ©ç”¨ç¼“å­˜
api = EnhancedArxivAPI()

# ç¬¬ä¸€æ¬¡è¯·æ±‚
papers1 = api.search_papers(query="machine learning")

# ç¬¬äºŒæ¬¡ç›¸åŒè¯·æ±‚ä¼šä½¿ç”¨ç¼“å­˜
papers2 = api.search_papers(query="machine learning")
```

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æœç´¢ç‰¹å®šä½œè€…çš„æ‰€æœ‰è®ºæ–‡ï¼Ÿ
A: ä½¿ç”¨ä½œè€…å­—æ®µæœç´¢ï¼š
```python
query = SearchQuery(
    terms=["Geoffrey Hinton"],
    field=SearchField.AUTHOR
)
papers = api.search_papers(query=query, max_results=100)
```

### Q: å¦‚ä½•è·å–æœ€æ–°çš„è®ºæ–‡ï¼Ÿ
A: æŒ‰æäº¤æ—¥æœŸé™åºæ’åºï¼š
```python
papers = api.search_papers(
    categories=["cs.AI"],
    sort_by=SortBy.SUBMITTED_DATE,
    sort_order=SortOrder.DESCENDING,
    max_results=20
)
```

### Q: å¦‚ä½•æœç´¢å¤šä¸ªå…³é”®è¯ï¼Ÿ
A: ä½¿ç”¨å¤šä¸ªæœ¯è¯­ï¼š
```python
query = SearchQuery(
    terms=["neural network", "deep learning"],
    operator="OR"
)
```

### Q: å¦‚ä½•é™åˆ¶æœç´¢çš„æ—¶é—´èŒƒå›´ï¼Ÿ
A: ä½¿ç”¨æ—¥æœŸèŒƒå›´ï¼š
```python
date_range = DateRange(
    start_date="2023-01-01",
    end_date="2023-12-31"
)
papers = api.search_papers(
    query="machine learning",
    date_range=date_range
)
```

## æ›´æ–°æ—¥å¿—

### v1.0.0 (å½“å‰ç‰ˆæœ¬)
- åŸºäº arXiv API å®˜æ–¹æ–‡æ¡£é‡æ–°æ„å»º
- æ·»åŠ ç»“æ„åŒ–æŸ¥è¯¢æ”¯æŒ
- å¢å¼ºé”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- æ”¯æŒå¤šå­—æ®µæœç´¢å’Œå¤æ‚æŸ¥è¯¢
- æ·»åŠ ä¾¿åˆ©å‡½æ•°
- å®Œæ•´çš„å‘åå…¼å®¹æ€§
- å¢å¼ºçš„ Paper æ¨¡å‹ï¼ˆæ·»åŠ  commentã€journal_refã€doi å­—æ®µï¼‰

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªåŸé¡¹ç›®çš„è®¸å¯è¯ã€‚